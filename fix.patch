diff --git a/logger.py b/logger.py
@@
-import json, datetime as dt, pathlib
-from config import TIMEZONE
-
-LOG_DIR=pathlib.Path(__file__).with_suffix('').parent / "log"
-LOG_DIR.mkdir(exist_ok=True)
-
-def event_to_dict(ev):
-    return {
-        "id": ev.get("id"),
-        "summary": ev.get("summary"),
-        "start": ev["start"],
-        "end":   ev["end"],
-        "color": ev.get("colorId"),
-    }
-
-def write_run_log(before, actions, after, trace, plan):
-    ts=dt.datetime.now().strftime("%Y%m%d_%H%M%S")
-    fname=LOG_DIR/f"run_{ts}.json"
-    payload = {
-        "before":   before,
-        "actions":  actions,
-        "after":    after,
-        "cmd_trace": trace,
-        "plan":     plan
-    }
-    fname.write_text(json.dumps(payload, indent=2, ensure_ascii=False))
-    print(f"[log] zapisano {fname}")
+"""
+Structured logger – JSONL, rotacja dzienna
+"""
+from __future__ import annotations
+import json, logging, logging.handlers, datetime as dt, pathlib, uuid
+
+LOG_DIR = pathlib.Path(__file__).with_suffix("").parent / "log"
+LOG_DIR.mkdir(exist_ok=True)
+
+class JSONFormatter(logging.Formatter):
+    def format(self, record):
+        base = {
+            "ts": dt.datetime.utcnow().isoformat(timespec="seconds") + "Z",
+            "level": record.levelname.lower(),
+            "msg": record.getMessage(),
+        }
+        if record.args:
+            base["data"] = record.args
+        return json.dumps(base, ensure_ascii=False)
+
+_handler = logging.handlers.TimedRotatingFileHandler(
+    LOG_DIR / "run.jsonl", when="midnight", backupCount=14, encoding="utf-8"
+)
+_handler.setFormatter(JSONFormatter())
+LOGGER = logging.getLogger("vendo_sync")
+LOGGER.setLevel(logging.INFO)
+LOGGER.addHandler(_handler)
+
+# convenience -----------------------------------------------------------------
+
+def event_to_dict(ev):
+    return {
+        "id": ev.get("id"),
+        "summary": ev.get("summary"),
+        "start": ev["start"],
+        "end":   ev["end"],
+        "color": ev.get("colorId"),
+    }
+
+def log_run_snapshot(label: str, payload: dict):
+    LOGGER.info(label, payload)
+
+def new_run_id() -> str:
+    return uuid.uuid4().hex[:8]
diff --git a/main.py b/main.py
@@
-import logger
+import logger
@@
-    trace = [f"list_events => {len(all_ev)} ev",
+    run_id = logger.new_run_id()
+    trace = [f"run {run_id} start",
+             f"list_events => {len(all_ev)} ev",
              f"vendo => {len(vendo)}",
              f"other_events => {len(other_events)}"]
@@
-    logger.write_run_log(snap_before, actions, snap_after, trace, plan)
+    logger.log_run_snapshot("snapshot_before", {"run": run_id, "events": snap_before})
+    logger.log_run_snapshot("actions",        {"run": run_id, "list": actions})
+    logger.log_run_snapshot("snapshot_after", {"run": run_id, "events": snap_after})
+    logger.log_run_snapshot("trace",          {"run": run_id, "steps": trace})
+    logger.log_run_snapshot("plan",           {"run": run_id, **plan})
@@
-    print(f"Akcje: {len(actions)}")
+    print(f"[run {run_id}] Akcje: {len(actions)}")
+
+if __name__ == "__main__":
+    try:
+        run()
+    except Exception as e:
+        logger.LOGGER.exception("fatal error", {"error": str(e)})
+        raise
+
+```

---

**Po uruchomieniu** nowy plik `log/run.jsonl` będzie wyglądał tak
(1 wpis = 1 linia):

```json
{"ts":"2025-05-15T15:02:10Z","level":"info","msg":"snapshot_before","data":{"run":"a3b7c9d1","events":[...]}}
{"ts":"2025-05-15T15:02:10Z","level":"info","msg":"actions","data":{"run":"a3b7c9d1","list":[...]}}
{"ts":"2025-05-15T15:02:10Z","level":"info","msg":"snapshot_after","data":{"run":"a3b7c9d1","events":[...]}}
{"ts":"2025-05-15T15:02:10Z","level":"info","msg":"trace","data":{"run":"a3b7c9d1","steps":["run a3b7c9d1 start","list_events => 17 ev",...]} }
{"ts":"2025-05-15T15:02:10Z","level":"info","msg":"plan","data":{"run":"a3b7c9d1","locked":[...],"movable":[...],"scheduled":[...]}}
